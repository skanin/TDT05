{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "X = df_train.drop(['target', 'id'], axis=1)\n",
    "y = df_train['target']\n",
    "\n",
    "X_test = df_test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>AU</td>\n",
       "      <td>134e98eb8</td>\n",
       "      <td>be42001f3</td>\n",
       "      <td>6.8928</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PS</td>\n",
       "      <td>a</td>\n",
       "      <td>0f94eb834</td>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1d2ee04de</td>\n",
       "      <td>3.0</td>\n",
       "      <td>be0264098</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1d2ee04de</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232792002</td>\n",
       "      <td>3aad93cab</td>\n",
       "      <td>6.8098</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>G</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DT</td>\n",
       "      <td>f</td>\n",
       "      <td>5859a8a06</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>e06abf51f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71fb03996</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>e06abf51f</td>\n",
       "      <td>k</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>JP</td>\n",
       "      <td>64e2a3589</td>\n",
       "      <td>90116a97d</td>\n",
       "      <td>6.7761</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>5.0</td>\n",
       "      <td>vq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>vq</td>\n",
       "      <td>c</td>\n",
       "      <td>7d7c02c57</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5d1ac7760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>bf987f83f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5d1ac7760</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K</td>\n",
       "      <td>IT</td>\n",
       "      <td>960cdb2ef</td>\n",
       "      <td>dc4ee566b</td>\n",
       "      <td>6.9302</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bx</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bx</td>\n",
       "      <td>a</td>\n",
       "      <td>165e81a00</td>\n",
       "      <td>F</td>\n",
       "      <td>K</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>b0ab8b134</td>\n",
       "      <td>3.0</td>\n",
       "      <td>d40fcead7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>63.0</td>\n",
       "      <td>b0ab8b134</td>\n",
       "      <td>i</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H</td>\n",
       "      <td>AU</td>\n",
       "      <td>8377590c9</td>\n",
       "      <td>f09cc205f</td>\n",
       "      <td>7.0238</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>G</td>\n",
       "      <td>5.0</td>\n",
       "      <td>kB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kB</td>\n",
       "      <td>d</td>\n",
       "      <td>35309e01b</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0764632bc</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0764632bc</td>\n",
       "      <td>h</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  f0   f1         f2         f3      f4 f5   f6 f7   f8  f9   f10 f11 f12  \\\n",
       "0  I   AU  134e98eb8  be42001f3  6.8928  B  0.0  R  4.0  PS   1.0  PS   a   \n",
       "1  N  NaN  232792002  3aad93cab  6.8098  A  1.0  G  6.0  DT  10.0  DT   f   \n",
       "2  P   JP  64e2a3589  90116a97d  6.7761  A  0.0  R  5.0  vq   0.0  vq   c   \n",
       "3  K   IT  960cdb2ef  dc4ee566b  6.9302  A  0.0  R  5.0  Bx   1.0  Bx   a   \n",
       "4  H   AU  8377590c9  f09cc205f  7.0238  A  1.0  G  5.0  kB   0.0  kB   d   \n",
       "\n",
       "         f13 f14 f15   f16  f17        f18  f19        f20  f21  f22 f23 f24  \\\n",
       "0  0f94eb834   T   I   9.0  0.4  1d2ee04de  3.0  be0264098  3.0  0.0   B   N   \n",
       "1  5859a8a06   T   N  12.0  0.5  e06abf51f  1.0  71fb03996  3.0  1.0   F   N   \n",
       "2  7d7c02c57   T   P   5.0  0.2  5d1ac7760  2.0  bf987f83f  3.0  0.0   C   S   \n",
       "3  165e81a00   F   K   2.0  0.4  b0ab8b134  3.0  d40fcead7  2.0  0.0   D   N   \n",
       "4  35309e01b   T   H   8.0  0.6  0764632bc  6.0        NaN  2.0  1.0   A   S   \n",
       "\n",
       "    f25        f26 f27  f28  \n",
       "0  51.0  1d2ee04de   m  1.0  \n",
       "1  10.0  e06abf51f   k  1.0  \n",
       "2  16.0  5d1ac7760   c  0.0  \n",
       "3  63.0  b0ab8b134   i  1.0  \n",
       "4  26.0  0764632bc   h  1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first note we can take is that the data is that we do not know what the different features are. \n",
    "\n",
    "At first glance, we can see that some of the features looks categorical (eg. f14 and f7)\n",
    "\n",
    "Further, we see that there are some NaN values, which needs to be handeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAosAAAIICAYAAAAGzqRhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuR0lEQVR4nO3df7RlZX3n+fdnLoKWsQoDKFglXKqbmGYE1D4R07GTlBSmEFvoHtdqsghJDPbtsiYpsePESjKLWVn5Y0jHiaYnMbXuoDE9MdpGMHFZltGZmDgZgXAKkQtcJUQrykWDhXhRyQAF3/njnDI35d33575n36p6v9Y6q87Zz3P28629NnU/PPs+e6eqkCRJkubz33VdgCRJktYvw6IkSZIaGRYlSZLUyLAoSZKkRoZFSZIkNTIsSpIkqdFJXQ5++umn1/j4eJclSJIknfAOHDhwqKrOmK+t07A4Pj5Ov9/vsgRJkqQTXpK/a2rzMrQkSZIaGRYlSZLUqNPL0FMzs4zv2ddlCZIk6QR28IbLuy5h3VvSzGKS3Ummk1SSu5JMJflMkovm9HlLknuS3J3k/UmeuXZlS5IkaRSWehl6F3Ap8CPAj1XVBcCvA5MASTYDu4FeVb0YGAOuar9cSZIkjdKiYTHJXmArsB+4uKoeGTbdCmyZ0/Uk4FlJTgI2AA+2XKskSZJGbNGwWFU7GQS/bVX1jjlN1zIIkFTVDPB24MvAV4HZqvrEfPtLMpGkn6T/1GOzq61fkiRJa2hFq6GTbGMQFt82/Pxc4ArgXOAFwLOT/NR8362qyarqVVVvbMOmlVUtSZKkkVh2WExyIXAjcEVVPTzcvB34UlV9vaqeBG4G/lV7ZUqSJKkLywqLSc5mEASvqar75jR9GXhFkg1JAlwCTLdXpiRJkrqw3PssXg+cBrxrkAk5PLykfFuSDwF3AIeBzzJcKb2QCzZvou/9jSRJktatVFVng/d6vfLZ0JIkSd1KcqCqevO1+bg/SZIkNTIsSpIkqZFhUZIkSY0Mi5IkSWpkWJQkSVIjw6IkSZIaGRYlSZLUaLk35W7V1Mws43v2dVmCJEk6wRz0gSDLsujMYpLdSaaTVJK7kkwl+UySi4btL0py55zXo0muW/PKJUmStOaWMrO4C9gOnA1MV9UjSS5j8Di/i6vqC8BLAJKMATPAh9emXEmSJI3SgjOLSfYCW4H9DILhI8OmW4Et83zlEuBvq+rvWq1SkiRJnVhwZrGqdibZAWyrqkNzmq5lECCPdhXw/oX2mWQCmAAY23jG8qqVJEnSSC17NXSSbQzC4tuO2n4y8Drgjxf6flVNVlWvqnpjGzYtd3hJkiSN0LJWQye5ELgRuKyqHj6q+TLgjqr6+7aKkyRJUreWPLOY5GzgZuCaqrpvni4/ySKXoCVJknRsWc7M4vXAacC7kgAcrqoeQJJnA5cC/3E5g1+weRN973UkSZK0bi0aFqtqfPj2jcPXfH2+wyBISpIk6Tji4/4kSZLUyLAoSZKkRoZFSZIkNTIsSpIkqZFhUZIkSY0Mi5IkSWpkWJQkSVKjRe+zmGQ38CbgB4EpIMC3gDdV1eeGfU5l8BjAFwMF/FxV3bLYvqdmZhnfs2/FxUuSJK0HB4/jh4ws5Qkuu4DtwNnAdFU9kuQyYBK4eNjnt4GPV9Xrk5wMbFiTaiVJkjRSC16GTrIX2ArsBy6uqkeGTbcCW4Z9NgE/CrwboKqeqKpvrlXBkiRJGp0Fw2JV7QQeBLZV1TvmNF3LIEACnAt8Hfj9JJ9NcuPwWdGSJEk6xi17gUuSbQzC4tuGm04CXgb8XlW9FPgOsGeB708k6SfpP/XY7ApKliRJ0qgsKywmuZDBQpYrqurh4eYHgAeq6rbh5w8xCI/zqqrJqupVVW9sw6aV1CxJkqQRWXJYTHI2cDNwTVXdd2R7VX0N+EqSFw03XQLc22qVkiRJ6sRSVkMfcT1wGvCuJACHq6o3bPsF4H3DldBfBN7QapWSJEnqRKqqs8F7vV71+/3OxpckSRIkOTBnEvCf8AkukiRJamRYlCRJUiPDoiRJkhoZFiVJktTIsChJkqRGhkVJkiQ1MixKkiSp0XJuyt26qZlZxvfs67IESZKkZTl4w+VdlzBSi84sJtmdZDpJJbkryVSSzyS5aE6fg8PtdybxLtuSJEnHiaXMLO4CtgNnA9NV9UiSy4BJ4OI5/bZV1aE1qFGSJEkdWXBmMcleYCuwH7i4qh4ZNt0KbFnj2iRJktSxBcNiVe0EHmQwa/iOOU3XMgiQ3+0KfCLJgSQT7ZcpSZKkLix7gUuSbQzC4ivnbH5lVc0keR7wySSfr6pPN3x/ApgAGNt4xgpKliRJ0qgs69Y5SS4EbgSuqKqHj2yvqpnhnw8BHwZe3rSPqpqsql5V9cY2bFpZ1ZIkSRqJJYfFJGcDNwPXVNV9c7Y/O8lzjrwHXg3c3XahkiRJGr3lXIa+HjgNeFcSgMNV1QOeD3x4uO0k4I+q6uNtFypJkqTRS1V1Nniv16t+39sySpIkdSnJgeEk4PfwcX+SJElqZFiUJElSI8OiJEmSGhkWJUmS1MiwKEmSpEaGRUmSJDUyLEqSJKnRsp8N3aapmVnG9+zrsgRJkqTWHbzh8q5LaM2SZhaT7E4ynaSS3JVkKslnklx0VL+xJJ9N8tG1KVeSJEmjtNSZxV3AduBsYLqqHklyGTAJXDyn35uBaWBjq1VKkiSpE4vOLCbZC2wF9gMXV9Ujw6ZbgS1z+m0BLgduXIM6JUmS1IFFZxarameSHcC2qjo0p+laBgHyiHcCvwQ8Z6H9JZkAJgDGNp6x3HolSZI0QitaDZ1kG4Ow+Lbh59cCD1XVgcW+W1WTVdWrqt7Yhk0rGV6SJEkjsuzV0EkuZHCp+bKqeni4+UeA1yV5DfBMYGOSP6yqn2qvVEmSJI3asmYWk5wN3AxcU1X3HdleVb9cVVuqahy4Cvhzg6IkSdKxb7kzi9cDpwHvSgJwuKp6rVclSZKkdSFV1dngvV6v+v1+Z+NLkiQJkhxomgD0cX+SJElqZFiUJElSI8OiJEmSGhkWJUmS1MiwKEmSpEaGRUmSJDUyLEqSJKnRsh/316apmVnG9+zrsgRJkqTWHbzh8q5LaM2SZhaT7E4ynaSS3JVkKslnklw0bH9mkr9O8rkk9yT5tbUtW5IkSaOw1JnFXcB24GxguqoeSXIZMAlcDDwOvKqqvp3kGcBfJdlfVbeuSdWSJEkaiUVnFpPsBbYC+4GLq+qRYdOtwBaAGvj2cPszhq/uniMoSZKkViwaFqtqJ/AgsK2q3jGn6VoGARKAJGNJ7gQeAj5ZVbfNt78kE0n6SfpPPTa7quIlSZK0tla0GjrJNgZh8W1HtlXVU1X1EgazjS9P8uL5vltVk1XVq6re2IZNKxlekiRJI7LssJjkQuBG4Iqqevjo9qr6JvApYMeqq5MkSVKnlhUWk5wN3AxcU1X3zdl+RpJTh++fBVwKfL7FOiVJktSB5d5n8XrgNOBdSQAOV1UPOAv4gyRjDALoB6vqo61WKkmSpJFLVXeLlnu9XvX7/c7GlyRJEiQ5MJwA/B4+7k+SJEmNDIuSJElqZFiUJElSI8OiJEmSGhkWJUmS1MiwKEmSpEaGRUmSJDVa7k25WzU1M8v4nn1dliBJkrRsB2+4vOsSRmbRmcUku5NMJ6kkdyWZSvKZJBcN21+Y5FNJ7k1yT5I3r33ZkiRJGoWlzCzuArYDZwPTVfVIksuASeBi4DDwi1V1R5LnAAeSfLKq7l2zqiVJkjQSC84sJtkLbAX2AxdX1SPDpluBLQBV9dWqumP4/lvANLB5zSqWJEnSyCw4s1hVO5PsALZV1aE5TdcyCJD/RJJx4KXAbU37TDIBTACMbTxjBSVLkiRpVJa9wCXJNgZh8ZVHbf8+4Cbguqp6tOn7VTXJ4BI2p5x1Xi13fEmSJI3OssJikguBG4HLqurhOdufwSAovq+qbm63REmSJHVlyfdZTHI2cDNwTVXdN2d7gHczWPzyW+2XKEmSpK4sZ2bxeuA04F2DfMjhquoBPwJcA0wluXPY91eq6mOL7fCCzZvon0D3KZIkSTrWLBoWq2p8+PaNw9fR7X8FpN2yJEmStB74uD9JkiQ1MixKkiSpkWFRkiRJjQyLkiRJamRYlCRJUiPDoiRJkhoZFiVJktRo2c+GbtPUzCzje/Z1WYIkSdKCDp7gDxBZdGYxye4k00kqyV1JppJ8JslFc/q8J8lDSe5e23IlSZI0Sku5DL0LuJTBY/1+rKouAH4dmJzT573AjtarkyRJUqcWDItJ9gJbgf3AxVX1yLDpVmDLkX5V9WngG2tVpCRJkrqx4O8sVtXOJDuAbVV1aE7TtQwC5LIlmQAmAMY2nrGSXUiSJGlElr3AJck2BmHxlSsZsKomGV7CPuWs82ol+5AkSdJoLCssJrkQuBG4rKoeXpuSJEmStF4s+T6LSc4Gbgauqar71q4kSZIkrRfLmVm8HjgNeFcSgMNV1QNI8n7gx4HTkzwA/C9V9e7FdnjB5k30T/B7F0mSJK1ni4bFqhofvn3j8DVfn59ssSZJkiStEz7uT5IkSY0Mi5IkSWpkWJQkSVIjw6IkSZIaGRYlSZLUyLAoSZKkRoZFSZIkNVr2s6HbNDUzy/iefV2WIEmSNBIHj9EHkSxpZjHJ7iTTSSrJXUmmknwmyUVz+uxI8oUk9yfZs3YlS5IkaVSWOrO4C9gOnA1MV9UjSS4DJoGLk4wBvwtcCjwA3J7kI1V171oULUmSpNFYdGYxyV5gK7AfuLiqHhk23QpsGb5/OXB/VX2xqp4APgBcsQb1SpIkaYSW8mzonUl2ANuq6tCcpmsZBEiAzcBX5rQ9AFw83/6STAATAGMbz1hJzZIkSRqRFS1wSbKNQVh85XK/W1WTDC5fc8pZ59VKxpckSdJoLDssJrkQuBG4rKoeHm6eAV44p9uW4TZJkiQdw5Z1n8UkZwM3A9dU1X1zmm4HzktybpKTgauAj7RXpiRJkrqw3JnF64HTgHclAThcVb2qOpzk54E/A8aA91TVPYvt7ILNm+gfo/cckiRJOhEsKSxW1fjw7RuHr/n6fAz4WDtlSZIkaT3wcX+SJElqZFiUJElSI8OiJEmSGhkWJUmS1MiwKEmSpEaGRUmSJDUyLEqSJKnRovdZTLIbeBNwL/AC4GXAr1bV2+f0eTPwH4AA/0dVvXMpg0/NzDK+Z98KypYkSTo+HFznDyhZyk25dwHbgSeAc4Ar5zYmeTGDoPjyYZ+PJ/loVd3fbqmSJEkatQUvQyfZC2wF9gNXV9XtwJNHdfsXwG1V9VhVHQb+Evh3a1GsJEmSRmvBsFhVO4EHgW1V9Y6GbncD/zrJaUk2AK8BXthumZIkSerCkp4NvZCqmk7yG8AngO8AdwJPNfVPMgFMAIxtPGO1w0uSJGkNtbIauqreXVX/sqp+FHgEuG+BvpNV1auq3tiGTW0ML0mSpDWy6plFgCTPq6qHkpzN4PcVX9HGfiVJktStJYfFJGcCfWAj8HSS64Dzq+pR4KYkpzFY/PI/VtU316BWSZIkjViqqrPBe71e9fv9zsaXJEkSJDlQVb352nyCiyRJkhoZFiVJktTIsChJkqRGhkVJkiQ1MixKkiSpkWFRkiRJjQyLkiRJatTKE1xWampmlvE9+7osQZIkadUO3nB51yWsmSXNLCbZnWQ6yU1JbknyeJK3HtXnLUnuSXJ3kvcneebalCxJkqRRWerM4i5gO/AEcA5w5dzGJJuB3Qwe//cPST4IXAW8t7VKJUmSNHKLziwm2QtsBfYDV1fV7QyeAX20k4BnJTkJ2AA82GahkiRJGr1FZxarameSHcC2qjrU0GcmyduBLwP/AHyiqj7RbqmSJEkatVZWQyd5LnAFcC7wAuDZSX6qoe9Ekn6S/lOPzbYxvCRJktZIW7fO2Q58qaq+XlVPAjcD/2q+jlU1WVW9quqNbdjU0vCSJElaC22FxS8Dr0iyIUmAS4DplvYtSZKkjizrPotJzgT6wEbg6STXMVgBfVuSDwF3AIeBzwKTLdcqSZKkEUtVdTZ4r9erfr/f2fiSJEmCJAeqqjdfm4/7kyRJUiPDoiRJkhoZFiVJktTIsChJkqRGhkVJkiQ1MixKkiSpkWFRkiRJjZZ1U+62Tc3MMr5nX5clSJKkE8jBGy7vuoRjzqIzi0l2J5lOclOSW5I8nuStc9pflOTOOa9Hh092kSRJ0jFuKTOLu4DtwBPAOcCVcxur6gvASwCSjAEzwIfbLFKSJEndWHBmMcleYCuwH7i6qm4HnlzgK5cAf1tVf9deiZIkSerKgjOLVbUzyQ5gW1UdWsL+rgLe30plkiRJ6lxrq6GTnAy8DvjjRfpNJOkn6T/12Gxbw0uSJGkNtHnrnMuAO6rq7xfqVFWTVdWrqt7Yhk0tDi9JkqS2tRkWfxIvQUuSJB1XlnyfxSRnAn1gI/D08PY451fVo0meDVwK/Mc1qVKSJEmdSFV1Nniv16t+v9/Z+JIkSYIkB6qqN1+bj/uTJElSI8OiJEmSGhkWJUmS1MiwKEmSpEaGRUmSJDUyLEqSJKmRYVGSJEmNlnxT7rUwNTPL+J59XZYgSZK0agdvuLzrEtbMojOLSXYnmU5yU5Jbkjye5K1H9Tk1yYeSfH7Y94fXrmRJkiSNylJmFncB24EngHOAK+fp89vAx6vq9UlOBja0VqEkSZI6s+DMYpK9wFZgP3B1Vd0OPHlUn03AjwLvBqiqJ6rqm2tSrSRJkkZqwbBYVTuBB4FtVfWOhm7nAl8Hfj/JZ5PcmOTZTftMMpGkn6T/1GOzKy5ckiRJa6+N1dAnAS8Dfq+qXgp8B9jT1LmqJquqV1W9sQ2bWhhekiRJa6WNsPgA8EBV3Tb8/CEG4VGSJEnHuFWHxar6GvCVJC8abroEuHe1+5UkSVL3lnyfxSRnAn1gI/B0kuuA86vqUeAXgPcNV0J/EXjDGtQqSZKkEUtVdTZ4r9erfr/f2fiSJEmCJAeqqjdfm4/7kyRJUiPDoiRJkhoZFiVJktTIsChJkqRGhkVJkiQ1MixKkiSpkWFRkiRJjZZ8U+61MDUzy/iefV2WIEmStGoHb7i86xLWzKIzi0l2J5lOclOSW5I8nuStR/U5mGQqyZ1JvMu2JEnScWIpM4u7gO3AE8A5wJUN/bZV1aGW6pIkSdI6sODMYpK9wFZgP3B1Vd0OPDmKwiRJktS9BcNiVe0EHmQwa/iOhboCn0hyIMnEQvtMMpGkn6T/1GOzy69YkiRJI9PWApdXVtVMkucBn0zy+ar69Hwdq2oSmAQ45azzqqXxJUmStAZauXVOVc0M/3wI+DDw8jb2K0mSpG6tOiwmeXaS5xx5D7wauHu1+5UkSVL3lnwZOsmZQB/YCDyd5DrgfOB04MNJjuzvj6rq4+2XKkmSpFFLVXe/Ntjr9arf97aMkiRJXUpyoKp687X5uD9JkiQ1MixKkiSpkWFRkiRJjQyLkiRJamRYlCRJUiPDoiRJkhoZFiVJktSorWdDr8jUzCzje/Z1WYIkSdKSHbzh8q5LGLklzSwm2Z1kOslNSW5J8niSt87TbyzJZ5N8tP1SJUmSNGpLnVncBWwHngDOAa5s6PdmYJrBIwElSZJ0jFt0ZjHJXmArsB+4uqpuB56cp98W4HLgxraLlCRJUjcWnVmsqp1JdgDbqurQAl3fCfwS8JyF9pdkApgAGNt4xtIrlSRJ0si1sho6yWuBh6rqwGJ9q2qyqnpV1RvbsKmN4SVJkrRG2rp1zo8Ar0tyEPgA8Kokf9jSviVJktSRVsJiVf1yVW2pqnHgKuDPq+qn2ti3JEmSurOs+ywmORPoM1jt/HSS64Dzq+rRlQx+weZN9E/A+xVJkiQdK5YUFoczhkdsWaTvXwB/seKKJEmStG74uD9JkiQ1MixKkiSpkWFRkiRJjQyLkiRJamRYlCRJUiPDoiRJkhoZFiVJktRoWTflbtvUzCzje/Z1WYIkSdL3OOhDQ75rSTOLSXYnmU5yU5Jbkjye5K1z2p+Z5K+TfC7JPUl+be1KliRJ0qgsdWZxF7AdeAI4B7jyqPbHgVdV1beTPAP4qyT7q+rW1iqVJEnSyC06s5hkL7AV2A9cXVW3A0/O7VMD3x5+fMbwVS3XKkmSpBFbNCxW1U7gQWBbVb2jqV+SsSR3Ag8Bn6yq2xr6TSTpJ+k/9djsCsuWJEnSKLS2GrqqnqqqlwBbgJcneXFDv8mq6lVVb2zDpraGlyRJ0hpo/dY5VfVN4FPAjrb3LUmSpNFqJSwmOSPJqcP3zwIuBT7fxr4lSZLUnWXdZzHJmUAf2Ag8neQ64HzgLOAPkowxCKAfrKqPLra/CzZvou99jCRJktatJYXFqhqf83HLPF3uAl7aRkGSJElaP3zcnyRJkhoZFiVJktTIsChJkqRGhkVJkiQ1MixKkiSpkWFRkiRJjQyLkiRJarSsm3K3bWpmlvE9+7osQZIkqRUHj9MHjSw6s5hkd5LpJDcluSXJ40neOqf9hUk+leTeJPckefPalixJkqRRWcrM4i5gO/AEcA5w5VHth4FfrKo7kjwHOJDkk1V1b6uVSpIkaeQWnFlMshfYCuwHrq6q24En5/apqq9W1R3D998CpoHNa1OuJEmSRmnBmcWq2plkB7Ctqg4ttrMk4wyeEX3bAn0mgAmAsY1nLKtYSZIkjVZrq6GTfB9wE3BdVT3a1K+qJquqV1W9sQ2b2hpekiRJa6CVsJjkGQyC4vuq6uY29ilJkqTurTosJgnwbmC6qn5r9SVJkiRpvUhVLdwhOQj0GPx+Yx/YCDwNfBs4H7gQ+H+AqeF2gF+pqo8tNniv16t+v7/S2iVJktSCJAeqqjdf26K3zqmq8Tkft8zT5a+ArKw0SZIkrWc+7k+SJEmNDIuSJElqZFiUJElSI8OiJEmSGhkWJUmS1MiwKEmSpEaGRUmSJDVa9D6LSXYDbwLuBV4AvAz41ap6+5w+7wFeCzxUVS9e6uBTM7OM79m37KIlSZLmOnjD5V2XcNxaNCwCu4DtwBPAOcCV8/R5L/A7wH9tqzBJkiR1b8HL0En2AluB/cDVVXU78OTR/arq08A31qRCSZIkdWbBmcWq2plkB7Ctqg6NqCZJkiStEyNf4JJkIkk/Sf+px2ZHPbwkSZKWYeRhsaomq6pXVb2xDZtGPbwkSZKWwVvnSJIkqdGSw2KSM5M8APwn4H9O8kCSjcO29wO3AC8abr92bcqVJEnSKKWqOhu81+tVv9/vbHxJkiRBkgNV1ZuvzcvQkiRJamRYlCRJUiPDoiRJkhoZFiVJktTIsChJkqRGhkVJkiQ1MixKkiSp0UldDj41M8v4nn1dliBJkrRiB2+4vOsS1tySZhaT7E4yneSmJLckeTzJW4/qsyPJF5Lcn2TP2pQrSZKkUVrqzOIuYDvwBHAOcOXcxiRjwO8ClwIPALcn+UhV3dteqZIkSRq1RWcWk+wFtgL7gaur6nbgyaO6vRy4v6q+WFVPAB8Armi7WEmSJI3WojOLVbUzyQ5gW1Udaui2GfjKnM8PABe3UJ8kSZI6NPLV0EkmkvST9J96bHbUw0uSJGkZ2gqLM8AL53zeMtz2Papqsqp6VdUb27CppeElSZK0FtoKi7cD5yU5N8nJwFXAR1ratyRJkjqyrPssJjkT6AMbgaeTXAecX1WPJvl54M+AMeA9VXVP28VKkiRptFJVnQ3e6/Wq3+93Nr4kSZIgyYGq6s3X5uP+JEmS1MiwKEmSpEaGRUmSJDUyLEqSJKmRYVGSJEmNDIuSJElqZFiUJElSo2XdlLttUzOzjO/Z12UJkiTpOHDwhsu7LuG4taqwmGQ38Cbgi8ATwD8D/j/g56rq7tWXJ0mSpC6t9jL0LuBS4F7gzqq6EPhp4LdXW5gkSZK6t+KZxSR7ga3A/uGfOwCq6vNJxpM8v6r+vp0yJUmS1IUVzyxW1U7gQWAbg5nEfweQ5OXAOcCWNgqUJElSd9paDX0DcGqSO4FfAD4LPDVfxyQTSfpJ+k89NtvS8JIkSVoLrayGrqpHgTcAJAnwJQaLXubrOwlMApxy1nnVxviSJElaG63MLCY5NcnJw49vBD49DJCSJEk6hrV1n8V/AfxBkgLuAa5tab+SJEnqUKq6uxLc6/Wq3+93Nr4kSZIgyYGq6s3X5uP+JEmS1MiwKEmSpEaGRUmSJDUyLEqSJKmRYVGSJEmNDIuSJElqZFiUJElSo7Zuyr0iUzOzjO/Z12UJkiRJ/8TBGy7vuoR1ZVVhMclu4E3A54f7Onv459ur6vdXX54kSZK6tNrL0LuAS4HbgXur6iLgx4H/bc6zoiVJknSMWnFYTLIX2ArsBwp4TpIA3wd8AzjcSoWSJEnqzIovQ1fVziQ7gG3A48BHgAeB5wD/vqqenu97SSaACYCxjWesdHhJkiSNQFuroX8CuBN4AfAS4HeSbJyvY1VNVlWvqnpjGza1NLwkSZLWQlth8Q3AzTVwP/Al4Adb2rckSZI60lZY/DJwCUCS5wMvAr7Y0r4lSZLUkbbus/jrwHuTTAEB3lZVh1ratyRJkjqSqups8F6vV/1+v7PxJUmSBEkOVFVvvjYf9ydJkqRGhkVJkiQ1MixKkiSpkWFRkiRJjQyLkiRJamRYlCRJUiPDoiRJkhq1dVPuFZmamWV8z74uS5AkSRqpgzdc3nUJy7KqmcUku5NMJ/lOkjuHr7uTPJXk+9sqUpIkSd1Y7cziLmB7VT1wZEOSfwO8paq+scp9S5IkqWMrnllMshfYCuxP8pY5TT8JvH+1hUmSJKl7K55ZrKqdSXYA26rqEECSDcAO4OebvpdkApgAGNt4xkqHlyRJ0gi0vRr63wD/70KXoKtqsqp6VdUb27Cp5eElSZLUprbD4lV4CVqSJOm40VpYTLIJ+DHgT9vapyRJkrrV5n0W/y3wiar6zlK/cMHmTfSPsXsNSZIknUhWFRaranzO+/cC711dOZIkSVpPfNyfJEmSGhkWJUmS1MiwKEmSpEaGRUmSJDUyLEqSJKmRYVGSJEmNDIuSJElq1OZNuZdtamaW8T37uixBkiRppA4eYw8kWdXMYpLdSaaTvC/Jjye5M8k9Sf6yrQIlSZLUndXOLO4CtgPfBj4D7KiqLyd53qorkyRJUudWHBaT7AW2AvuBDwA3V9WXAarqoXbKkyRJUpdWfBm6qnYCDwLbgDOA5yb5iyQHkvx00/eSTCTpJ+k/9djsSoeXJEnSCLS1wOUk4F8ClwDPAm5JcmtV3Xd0x6qaBCYBTjnrvGppfEmSJK2BtsLiA8DDVfUd4DtJPg1cBHxPWJQkSdKxo637LP4p8MokJyXZAFwMTLe0b0mSJHWklZnFqppO8nHgLuBp4Maqunux712weRP9Y+xeQ5IkSSeSVYXFqhqf8/43gd9cbUGSJElaP3zcnyRJkhoZFiVJktTIsChJkqRGhkVJkiQ1MixKkiSpkWFRkiRJjQyLkiRJatTW4/5WZGpmlvE9+7osQZIkaV05uM4eWLKqmcUku5NMJ5lJMpvkzuHr+rYKlCRJUndWO7O4C9gO/HPgrVX12tWXJEmSpPVixTOLSfYCW4H9wEtbq0iSJEnrxorDYlXtBB4EtgGfBX44yeeS7E/y3zd9L8lEkn6S/lOPza50eEmSJI1AW6uh7wDOqaqLgP8d+JOmjlU1WVW9quqNbdjU0vCSJElaC62Exap6tKq+PXz/MeAZSU5vY9+SJEnqTithMcmZSTJ8//Lhfh9uY9+SJEnqTlv3WXw98KYkh4F/AK6qqlrsSxds3kR/nd1LSJIkSf9oVWGxqsaHb39n+JIkSdJxxMf9SZIkqZFhUZIkSY0Mi5IkSWpkWJQkSVIjw6IkSZIaGRYlSZLUyLAoSZKkRm3dlHtFpmZmGd+zr8sSJEnSMeCgD/HozKpmFpPsTjKd5H3Dzz+U5HCS17dTniRJkrq02pnFXcD2qnogyRjwG8AnVl+WJEmS1oMVh8Uke4GtwP4k7wEKuAn4oZZqkyRJUsdWHBarameSHcA24BTgj4bvFwyLSSaACYCxjWesdHhJkiSNQFurod8JvK2qnl6sY1VNVlWvqnpjGza1NLwkSZLWQluroXvAB5IAnA68JsnhqvqTlvYvSZKkDrQSFqvq3CPvk7wX+KhBUZIk6djX6X0WL9i8ib73TZIkSVq3VhUWq2p8nm0/u5p9SpIkaf3wcX+SJElqZFiUJElSI8OiJEmSGhkWJUmS1MiwKEmSpEaGRUmSJDUyLEqSJKnRqu6zmGQ38CbgTOArwNPAYeC6qvqrxb4/NTPL+J59qylBkiRpJA6eoA8SWe0TXHYB24FvAt+pqkpyIfBB4AdXuW9JkiR1bMWXoZPsBbYC+4H/UFU1bHo2UI1flCRJ0jFjxTOLVbUzyQ5gW1UdSvJvgf8VeB5wYs7TSpIkHWdaW+BSVR+uqh8ErgR+valfkokk/ST9px6bbWt4SZIkrYHWV0NX1aeBrUlOb2ifrKpeVfXGNmxqe3hJkiS1qJWwmOSfJ8nw/cuAU4CH29i3JEmSurPa1dBH/A/ATyd5EvgH4N/PWfAiSZKkY1S6zHS9Xq/6/X5n40uSJAmSHKiq3nxtPsFFkiRJjQyLkiRJamRYlCRJUiPDoiRJkhoZFiVJktTIsChJkqRGhkVJkiQ1auum3CsyNTPL+J59XZYgSZK0JAdvuLzrEjqxqpnFJLuTTCepJHclmUrymSQXtVWgJEmSurPamcVdwHbgbGC6qh5JchkwCVy82uIkSZLUrRXPLCbZC2wF9gMXV9Ujw6ZbgS0t1CZJkqSOrXhmsap2JtkBbKuqQ3OarmUQICVJknSMa3WBS5JtDMLiKxfoMwFMAIxtPKPN4SVJktSy1m6dk+RC4Ebgiqp6uKlfVU1WVa+qemMbNrU1vCRJktZAK2ExydnAzcA1VXVfG/uUJElS99q6DH09cBrwriQAh6uq19K+JUmS1JFUVWeD93q96vf7nY0vSZIkSHKgaaLPx/1JkiSpkWFRkiRJjQyLkiRJamRYlCRJUiPDoiRJkhoZFiVJktTIsChJkqRGrT4bermmZmYZ37OvyxIkSdIJ4OANl3ddwjFrVTOLSXYnmU5yU5Jbkjye5K1tFSdJkqRurXZmcRewHXgCOAe4crUFSZIkaf1Y8cxikr3AVmA/cHVV3Q482VZhkiRJ6t6KZxarameSHcC2qjq01O8lmQAmAMY2nrHS4SVJkjQCI18NXVWTVdWrqt7Yhk2jHl6SJEnL4K1zJEmS1MiwKEmSpEat3GcxyZlAH9gIPJ3kOuD8qnq0jf1LkiSpG6sKi1U1PufjluV+/4LNm+h7k0xJkqR1y8vQkiRJamRYlCRJUiPDoiRJkhoZFiVJktTIsChJkqRGhkVJkiQ1MixKkiSpUSs35V6pqZlZxvfs67IESZKkVTt4HN83elUzi0l2J5lO8r4k/yXJ/UnuSvKytgqUJElSd1Z7GXoXcCnwPuC84WsC+L1V7leSJEnrwIovQyfZC2wF9gM/APxsVRVwa5JTk5xVVV9tqU5JkiR1YMUzi1W1E3gQ2AZ8EvjKnOYHgM3zfS/JRJJ+kv5Tj82udHhJkiSNwMhXQ1fVZFX1qqo3tmHTqIeXJEnSMrQVFmeAF875vGW4TZIkScewtsLiR4CfzsArgFl/X1GSJOnY19Z9Fj8GvAa4H3gMeENL+5UkSVKHMljA3I1er1f9fr+z8SVJkgRJDlRVb742H/cnSZKkRoZFSZIkNTIsSpIkqVGnv7OY5FvAFzor4NhxOnCo6yKOER6rpfNYLZ3Hamk8TkvnsVo6j9XSreZYnVNVZ8zX0NZq6JX6QtMvU+ofJel7nJbGY7V0Hqul81gtjcdp6TxWS+exWrq1OlZehpYkSVIjw6IkSZIadR0WJzse/1jhcVo6j9XSeayWzmO1NB6npfNYLZ3HaunW5Fh1usBFkiRJ61vXM4uSJElaxzoJi0l2JPlCkvuT7OmihvUkyQuTfCrJvUnuSfLm4fbvT/LJJH8z/PO5w+1J8l+Gx++uJC/r9m8wWknGknw2yUeHn89NctvwePy3JCcPt58y/Hz/sH2808JHLMmpST6U5PNJppP8sOfU/JK8Zfjf3t1J3p/kmZ5XA0nek+ShJHfP2bbs8yjJzwz7/02Sn+ni77LWGo7Vbw7/G7wryYeTnDqn7ZeHx+oLSX5izvbj+mfkfMdpTtsvJqkkpw8/e07Nc6yS/MLwvLonyX+es31tzqmqGukLGAP+FtgKnAx8Djh/1HWspxdwFvCy4fvnAPcB5wP/Gdgz3L4H+I3h+9cA+4EArwBu6/rvMOLj9Z+APwI+Ovz8QeCq4fu9wJuG73cBe4fvrwL+W9e1j/g4/QHwxuH7k4FTPafmPU6bgS8Bz5pzPv2s59V3j8+PAi8D7p6zbVnnEfD9wBeHfz53+P65Xf/dRnSsXg2cNHz/G3OO1fnDn3+nAOcOfy6OnQg/I+c7TsPtLwT+DPg74HTPqcZzahvwfwGnDD8/b63PqS5mFl8O3F9VX6yqJ4APAFd0UMe6UVVfrao7hu+/BUwz+AF2BYMf+Az/vHL4/grgv9bArcCpSc4abdXdSLIFuBy4cfg5wKuADw27HH2cjhy/DwGXDPsf95JsYvCPzLsBquqJqvomnlNNTgKeleQkYAPwVTyvAKiqTwPfOGrzcs+jnwA+WVXfqKpHgE8CO9a8+BGb71hV1Seq6vDw463AluH7K4APVNXjVfUl4H4GPx+P+5+RDecUwDuAXwLmLqbwnPreY/Um4IaqenzY56Hh9jU7p7oIi5uBr8z5/MBwm4DhJa2XArcBz6+qrw6bvgY8f/j+RD6G72Twj8nTw8+nAd+c84/x3GPx3eM0bJ8d9j8RnAt8Hfj9DC7Z35jk2XhOfY+qmgHeDnyZQUicBQ7gebWQ5Z5HJ+z5dZSfYzBLBh6rfyLJFcBMVX3uqCaP0/f6AeBfD38N5i+T/NBw+5odKxe4rCNJvg+4Cbiuqh6d21aDOeYTeul6ktcCD1XVga5rOQacxODSxe9V1UuB7zC4XPhdnlMDw9+3u4JBwH4B8GyOwxmKteJ5tDRJfhU4DLyv61rWmyQbgF8Bru+6lmPESQwuv78C+J+AD6711Y0uwuIMg99LOGLLcNsJLckzGATF91XVzcPNf3/kUuDwzyNTzSfqMfwR4HVJDjKYRn8V8NsMLksceXTl3GPx3eM0bN8EPDzKgjv0APBAVd02/PwhBuHRc+p7bQe+VFVfr6ongZsZnGueV82Wex6dyOcXSX4WeC1w9TBcg8dqrn/G4H/WPjf8930LcEeSM/E4zecB4Obhpfm/ZnCl7XTW8Fh1ERZvB84brjQ8mcEviH+kgzrWjeH/EbwbmK6q35rT9BHgyAqvnwH+dM72nx6uEnsFMDvnktBxq6p+uaq2VNU4g/Pmz6vqauBTwOuH3Y4+TkeO3+uH/U+IGZCq+hrwlSQvGm66BLgXz6n5fBl4RZINw/8Wjxwrz6tmyz2P/gx4dZLnDmdyXz3cdtxLsoPBr868rqoem9P0EeCqDFbXnwucB/w1J+DPyKqaqqrnVdX48N/3Bxgs+vwanlPz+RMGi1xI8gMMFq0cYi3PqdWu1FnJi8HqpvsYrM751S5qWE8v4JUMLuPcBdw5fL2Gwe9B/d/A3zBY+fT9w/4Bfnd4/KaAXtd/hw6O2Y/zj6uhtw7/g7gf+GP+cYXYM4ef7x+2b+267hEfo5cA/eF59ScMVgx6Ts1/rH4N+DxwN/B/MlhN6Hk1+Pu+n8Hvcj7J4If4tSs5jxj8vt79w9cbuv57jfBY3c/g98WO/Nu+d07/Xx0eqy8Al83Zflz/jJzvOB3VfpB/XA3tOfW959TJwB8O/726A3jVWp9TPsFFkiRJjVzgIkmSpEaGRUmSJDUyLEqSJKmRYVGSJEmNDIuSJElqZFiUJElSI8OiJEmSGhkWJUmS1Oj/B/ZFNH75IQ0PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 792x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , ax = plt.subplots(figsize=(11,9))\n",
    "\n",
    "X.isna().sum().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that _all_ columns contains NaN values. This is a problem, as we only have 50000 rows to train our model on from the start. If we are to drop the NaN rows, we will be left with a pretty small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , ax = plt.subplots(figsize=(6,4))\n",
    "sns.countplot(x='target', data=df_train)\n",
    "plt.title(\"Count of Targets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent labeled 0: 81.272\n",
      "Percent labeled 1: 18.728\n"
     ]
    }
   ],
   "source": [
    "n = len(df_train)\n",
    "\n",
    "class_0 = len(df_train[df_train['target'] == 0])\n",
    "class_1 = len(df_train[df_train['target'] == 1])\n",
    "\n",
    "print(f'Percent labeled 0: {class_0*100/n}')\n",
    "print(f'Percent labeled 1: {class_1*100/n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the majority of the class labels are 0, meaning we have to be carefull considering overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "corr = X.corr(method='pearson')\n",
    "\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=bool), linewidths=.5, cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we see that there are no correlation between the numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the numerical and other features in two lists, so we can examine them separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = list(X.corr().columns)\n",
    "other_features = list(set(X.columns) - set(numerical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f15</th>\n",
       "      <th>f1</th>\n",
       "      <th>f11</th>\n",
       "      <th>f7</th>\n",
       "      <th>f5</th>\n",
       "      <th>f12</th>\n",
       "      <th>f24</th>\n",
       "      <th>f0</th>\n",
       "      <th>f2</th>\n",
       "      <th>f14</th>\n",
       "      <th>f23</th>\n",
       "      <th>f13</th>\n",
       "      <th>f3</th>\n",
       "      <th>f20</th>\n",
       "      <th>f27</th>\n",
       "      <th>f9</th>\n",
       "      <th>f26</th>\n",
       "      <th>f18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>AU</td>\n",
       "      <td>PS</td>\n",
       "      <td>R</td>\n",
       "      <td>B</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>I</td>\n",
       "      <td>134e98eb8</td>\n",
       "      <td>T</td>\n",
       "      <td>B</td>\n",
       "      <td>0f94eb834</td>\n",
       "      <td>be42001f3</td>\n",
       "      <td>be0264098</td>\n",
       "      <td>m</td>\n",
       "      <td>PS</td>\n",
       "      <td>1d2ee04de</td>\n",
       "      <td>1d2ee04de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DT</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>f</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>232792002</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>5859a8a06</td>\n",
       "      <td>3aad93cab</td>\n",
       "      <td>71fb03996</td>\n",
       "      <td>k</td>\n",
       "      <td>DT</td>\n",
       "      <td>e06abf51f</td>\n",
       "      <td>e06abf51f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>JP</td>\n",
       "      <td>vq</td>\n",
       "      <td>R</td>\n",
       "      <td>A</td>\n",
       "      <td>c</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>64e2a3589</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>7d7c02c57</td>\n",
       "      <td>90116a97d</td>\n",
       "      <td>bf987f83f</td>\n",
       "      <td>c</td>\n",
       "      <td>vq</td>\n",
       "      <td>5d1ac7760</td>\n",
       "      <td>5d1ac7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K</td>\n",
       "      <td>IT</td>\n",
       "      <td>Bx</td>\n",
       "      <td>R</td>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>K</td>\n",
       "      <td>960cdb2ef</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>165e81a00</td>\n",
       "      <td>dc4ee566b</td>\n",
       "      <td>d40fcead7</td>\n",
       "      <td>i</td>\n",
       "      <td>Bx</td>\n",
       "      <td>b0ab8b134</td>\n",
       "      <td>b0ab8b134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H</td>\n",
       "      <td>AU</td>\n",
       "      <td>kB</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>d</td>\n",
       "      <td>S</td>\n",
       "      <td>H</td>\n",
       "      <td>8377590c9</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>35309e01b</td>\n",
       "      <td>f09cc205f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h</td>\n",
       "      <td>kB</td>\n",
       "      <td>0764632bc</td>\n",
       "      <td>0764632bc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  f15   f1 f11 f7 f5 f12 f24 f0         f2 f14 f23        f13         f3  \\\n",
       "0   I   AU  PS  R  B   a   N  I  134e98eb8   T   B  0f94eb834  be42001f3   \n",
       "1   N  NaN  DT  G  A   f   N  N  232792002   T   F  5859a8a06  3aad93cab   \n",
       "2   P   JP  vq  R  A   c   S  P  64e2a3589   T   C  7d7c02c57  90116a97d   \n",
       "3   K   IT  Bx  R  A   a   N  K  960cdb2ef   F   D  165e81a00  dc4ee566b   \n",
       "4   H   AU  kB  G  A   d   S  H  8377590c9   T   A  35309e01b  f09cc205f   \n",
       "\n",
       "         f20 f27  f9        f26        f18  \n",
       "0  be0264098   m  PS  1d2ee04de  1d2ee04de  \n",
       "1  71fb03996   k  DT  e06abf51f  e06abf51f  \n",
       "2  bf987f83f   c  vq  5d1ac7760  5d1ac7760  \n",
       "3  d40fcead7   i  Bx  b0ab8b134  b0ab8b134  \n",
       "4        NaN   h  kB  0764632bc  0764632bc  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[other_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "corr = pd.get_dummies(X[other_features]).corr(method='pearson')\n",
    "\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=bool), linewidths=.5, cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_columns = ['f2', 'f3', 'f13', 'f18', 'f20', 'f26']\n",
    "ordinal_columns = ['f6', 'f4', 'f8', 'f16', 'f17', 'f19', 'f21', 'f25']\n",
    "categorical_columns = ['f1', 'f5', 'f7', 'f9', 'f11', 'f24']\n",
    "ordinal_cat_columns = ['f0', 'f12', 'f23', 'f27']\n",
    "binary_columns = ['f10', 'f28', 'f22', 'f14']\n",
    "all_columns = ['f' + str(i) for i in range(0, 29)]\n",
    "removed_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_hex(df: pd.DataFrame) -> None:\n",
    "    def conv_hex_map(x):\n",
    "        try:\n",
    "            return int(x, 16)\n",
    "        except ValueError as e:\n",
    "            return np.nan\n",
    "        except TypeError as e:\n",
    "            return np.nan\n",
    "\n",
    "    for col in hex_columns:\n",
    "        if col not in list(df.columns):\n",
    "            continue\n",
    "        col_loc = list(df.columns).index(col)\n",
    "        df[col] = df[col].apply(lambda x: conv_hex_map(x))\n",
    "\n",
    "\n",
    "def conv_bool(df: pd.DataFrame):\n",
    "    def conv_bool_map(x):\n",
    "        try:\n",
    "            if not type(x) == str:\n",
    "                return x\n",
    "            if x.lower() == 'f':\n",
    "                return 0\n",
    "            elif x.lower() == 't':\n",
    "                return 1\n",
    "            return x\n",
    "        except Exception as e:\n",
    "            return np.nan\n",
    "    df['f14'] = df['f14'].apply(lambda x: conv_bool_map(x))\n",
    "\n",
    "\n",
    "def conv_binary(df: pd.DataFrame):\n",
    "    def binaryToDecimal(binary):\n",
    "        try:\n",
    "            binary = int(binary)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "        binary1 = binary\n",
    "        decimal, i, n = 0, 0, 0\n",
    "        while(binary != 0):\n",
    "            dec = binary % 10\n",
    "            decimal = decimal + dec * pow(2, i)\n",
    "            binary = binary//10\n",
    "            i += 1\n",
    "        return decimal\n",
    "    for col in binary_columns:\n",
    "        if col not in list(df.columns):\n",
    "            continue\n",
    "    df[col] = df[col].apply(lambda x: binaryToDecimal(x))\n",
    "    \n",
    "def remove_duplicate_columns(df: pd.DataFrame) -> None:\n",
    "    cols_to_drop = []\n",
    "    cols = list(df.columns)\n",
    "    for col in df.columns:\n",
    "        if col in cols:\n",
    "            cols.remove(col)\n",
    "        for col2 in cols:\n",
    "            if df[col].equals(df[col2]):\n",
    "                cols_to_drop.append(col2)\n",
    "\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "def transform_categorical(df: pd.DataFrame, test=False) -> None:\n",
    "    cols = list(set(df.columns).intersection(set(categorical_columns).union(set(ordinal_cat_columns))))\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "        df[col] = df[col].cat.codes\n",
    "\n",
    "def remove_duplicates(df: pd.DataFrame) -> None:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "def conv_columns(df: pd.DataFrame, test=False) -> None:\n",
    "    conv_hex(df)\n",
    "    conv_bool(df)\n",
    "    conv_binary(df)\n",
    "    return transform_categorical(df, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mice():\n",
    "    infile = 'train_processed.csv'\n",
    "    outfile = 'train_imputed.csv'\n",
    "    # np.savetxt(infile, data.to_numpy().tolist(), delimiter=\",\")\n",
    "    os.system(f'type nul > {outfile}')\n",
    "    os.system('\"C:\\Program Files\\R\\R-4.1.1\\bin\\Rscript.exe\" --vanilla run_mice.R %s %s' % (infile, outfile))\n",
    "    data_imputed = pd.read_csv(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, test=False):\n",
    "    if test:\n",
    "        df.loc[26648, 'f9'] = np.nan\n",
    "        df.loc[20956, 'f15'] = np.nan\n",
    "        df.loc[21034, 'f15'] = np.nan\n",
    "        \n",
    "    remove_duplicate_columns(df)\n",
    "    remove_duplicates(df)\n",
    "\n",
    "    conv_columns(df, test)\n",
    "    \n",
    "    if test:\n",
    "        df.to_csv('./test_processed.csv', index=False)\n",
    "    else:\n",
    "        df.to_csv('./train_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess(df_train)\n",
    "preprocess(df_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(X_test_pre.isnull().sum()/len(X_test_pre.index)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "for col in X_train_pre:\n",
    "    if X_train_pre[col].isnull().sum() > 0:\n",
    "        X_train_pre[col].fillna(X_train_pre[col].mean(), inplace=True)\n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "X_cols = X_train_pre.columns\n",
    "\n",
    "X_train_pre, y_train_pre = sm.fit_resample(X_train_pre, y_train)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X_cols)\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(X : pd.DataFrame, y : pd.DataFrame, size=.2):\n",
    "    return train_test_split(X, y, test_size=size, stratify=y)\n",
    "\n",
    "def fit(data : pd.DataFrame, labels : pd.DataFrame, classifier : any, eval_pool = None) -> None:\n",
    "    if eval_pool is not None:\n",
    "        classifier.fit(data, labels, eval_set=eval_pool)\n",
    "    else:\n",
    "        classifier.fit(data, labels)\n",
    "\n",
    "def predict_proba(classifier : any, test : pd.DataFrame) -> np.array:\n",
    "    return classifier.predict_proba(test)\n",
    "\n",
    "def predict(classifier : any, test : pd.DataFrame) -> np.array:\n",
    "    return classifier.predict(test)\n",
    "\n",
    "def print_accuracy(pred : np.array, test : pd.DataFrame, name : str):\n",
    "    print(name + ' Model accuracy score: {0:0.4f}'.format(roc_auc_score(test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_data = pd.read_csv('train_imputed_f9_split.csv')\n",
    "\n",
    "X_train_pre = imp_data.drop(['target', 'id'], axis=1)\n",
    "y_train = imp_data['target']\n",
    "\n",
    "df_test = pd.read_csv('test_imputed_f9_split.csv')\n",
    "X_test_pre = df_test.drop('id', axis=1)\n",
    "\n",
    "train_cat = list(set(X_train_split.columns).intersection(set(categorical_columns)))\n",
    "\n",
    "for col in X_train_pre:\n",
    "    if X_train_pre[col].isnull().sum() > 0:\n",
    "        X_train_pre[col].fillna(method='bfill', inplace=True)\n",
    "    \n",
    "    # if col in train_cat:\n",
    "        # X_train_pre[col] = X_train_pre[col].astype('category')\n",
    "        \n",
    "for col in X_test_pre:\n",
    "    if X_test_pre[col].isnull().sum() > 0:\n",
    "        X_test_pre[col].fillna(method='bfill', inplace=True)\n",
    "    \n",
    "    # if col in train_cat:\n",
    "        # X_train_pre[col] = X_train_pre[col].astype('category')\n",
    "        \n",
    "remove_duplicate_columns(X_train_pre)\n",
    "remove_duplicate_columns(X_test_pre)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# cols_to_transform = list(set(X_train_pre.columns) - set(train_cat))\n",
    "\n",
    "# X_train_pre[cols_to_transform] = scaler.fit_transform(X_train_pre[cols_to_transform], y_train)\n",
    "# X_test_pre[cols_to_transform] = scaler.transform(X_test_pre[cols_to_transform])\n",
    "\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = split(X_train_pre, y_train, size=.2)\n",
    "        \n",
    "# X_train_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "train_cat = list(set(X_train_split.columns).intersection(set(categorical_columns)))\n",
    "test_cat = list(set(X_test_split.columns).intersection(set(categorical_columns)))\n",
    "cats = []\n",
    "for col in train_cat:\n",
    "    cats.append(X_train_pre.columns.get_loc(col))\n",
    "    \n",
    "print(cats)\n",
    "print(train_cat)\n",
    "print(test_cat)\n",
    "\n",
    "train_dataset = Pool(X_train_split ,y_train_split, cat_features=train_cat)\n",
    "test_dataset = Pool(X_test_split, y_test_split, cat_features=test_cat)\n",
    "\n",
    "model = CatBoostClassifier(loss_function='Logloss', eval_metric='AUC')\n",
    "\n",
    "eval_pool = Pool(X_test_split, y_test_split, cat_features=cats)\n",
    "\n",
    "# clf = CatBoostClassifier(loss_function='Logloss',cat_features=cats,eval_metric= 'AUC',depth= 1,learning_rate= 1,l2_leaf_reg= 5,iterations= 2000)\n",
    "\n",
    "clf = CatBoostClassifier(depth=1, learning_rate=1, iterations=2000, stratified=True)\n",
    "\n",
    "fit(X_train_pre, y_train, clf, eval_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'learning_rate': [0.03, 0.1, 1],\n",
    "        'depth': [1, 2, 4, 6, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5],\n",
    "        'iterations': [50, 100, 150, 500, 1000, 2000]}\n",
    "\n",
    "model.grid_search(grid,train_dataset, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(max_depth=6, eta=.125, objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "fit(X_train_split, y_train_split, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "fit(X_train_split, y_train_split, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=1000)\n",
    "fit(X_train_split, y_train_split, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre.loc[~(X_train_pre['f18'] == X_train_pre['f26'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "models['Catboost'] = CatBoostClassifier(iterations=2000, depth=1, learning_rate=1, verbose=False)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "models['Light GBM'] = LGBMClassifier()\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "models['GBM'] = GradientBoostingClassifier()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy, precision, recall, auc = {}, {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    # Fit the classifier model\n",
    "    models[key].fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Prediction \n",
    "    predictions = models[key].predict_proba(X_test_split )\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc[key] = roc_auc_score(y_test_split, predictions[:, 1])\n",
    "    \n",
    "\n",
    "df_model = pd.DataFrame(index=models.keys(), columns=['Auc'])\n",
    "df_model['Auc'] = auc.values()\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanderlindberg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Wall time: 3min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=StackingClassifier(cv=10,\n",
       "                                                estimators=[('lgbm',\n",
       "                                                             LGBMClassifier(device='gpu',\n",
       "                                                                            random_state=42))],\n",
       "                                                final_estimator=LogisticRegression()),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'lgbm__max_depth': [6, 7],\n",
       "                                        'lgbm__num_leaves': [70, 80]},\n",
       "                   scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = {}\n",
    "# models['rf'] = RandomForestClassifier(random_state=42)\n",
    "# models['Catboost'] = CatBoostClassifier(boosting_type='Plain', gpu_cat_features_storage = 'CpuPinnedMemory', max_ctr_complexity=1, iterations=1000, depth=1, learning_rate=1, verbose=False, random_state=42, task_type=\"GPU\", devices='0:1')\n",
    "models['lgbm'] = LGBMClassifier(random_state=42, device='gpu')\n",
    "# models['gbm'] = GradientBoostingClassifier(min_samples_split=500,min_samples_leaf=50,max_depth=8, subsample=0.8, random_state=42)\n",
    "# models['xgb'] = XGBClassifier(tree_method='gpu_hist', gpu_id=0, verbosity = 0)\n",
    "clf = StackingClassifier(estimators = list(models.items()), final_estimator=LogisticRegression(), cv=10)\n",
    "\n",
    "params = {# 'rf__n_estimators': [5, 10, 100], \n",
    "          'lgbm__max_depth': [6,7], \n",
    "          'lgbm__num_leaves': [70, 80], \n",
    "          # 'gbm__n_estimators': range(20,81,10), \n",
    "          # 'gbm__learning_rate': [1, .1, .01]\n",
    " #            'xgb__max_depth': [5, 10, 20],\n",
    " #            'xgb__n_estimators': [10, 100, 1000],\n",
    " #            'xgb__learning_rate': [1, .1, .01]\n",
    "        }\n",
    "\n",
    "# grid = GridSearchCV(estimator=clf, param_grid=params, cv=5, n_jobs=-1, scoring='roc_auc', refit=True, verbose=100)\n",
    "grid = RandomizedSearchCV(estimator=clf, param_distributions=params, n_iter=10, cv=5, n_jobs=-1, scoring='roc_auc', refit=True, verbose=10)\n",
    "grid.fit(X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 161 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "models = {}\n",
    "models['rf'] = RandomForestClassifier(random_state=42)\n",
    "models['Catboost'] = CatBoostClassifier(boosting_type='Plain', gpu_cat_features_storage = 'CpuPinnedMemory', max_ctr_complexity=1, iterations=1000, depth=1, learning_rate=1, verbose=False, random_state=42, task_type=\"GPU\", devices='0:1')\n",
    "models['lgbm'] = LGBMClassifier(random_state=42, device='gpu')\n",
    "models['gbm'] = GradientBoostingClassifier(min_samples_split=500,min_samples_leaf=50,max_depth=8, subsample=0.8, random_state=42)\n",
    "models['xgb'] = XGBClassifier(tree_method='gpu_hist', gpu_id=0, verbosity = 0, objective='binary:logistic', silent=True)\n",
    "\n",
    "\n",
    "# clf = StackingClassifier(estimators = list(models.items()), final_estimator=LogisticRegression(), cv=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def grid(estimator, params, n_jobs=-1):\n",
    "    grid_cv = GridSearchCV(estimator=estimator, param_grid=params, cv=5, n_jobs=n_jobs, scoring='roc_auc', refit=True, verbose=10)\n",
    "    grid_cv.fit(X_train_pre, y_train)\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best params lgbm: {'boosting_type': 'dart', 'colsample_bytree': 0.64, 'learning_rate': 1, 'max_bin': 255, 'n_estimators': 32, 'num_leaves': 16, 'objective': 'binary', 'subsample': 0.7}\n",
      "Best score lgbm: 0.7322889897844772\n",
      "Wall time: 3.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_params = {\n",
    "        'learning_rate': [1],\n",
    "        'n_estimators': [24, 32, 52],\n",
    "        'num_leaves': [16], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "        'boosting_type' : ['dart'], # for better accuracy -> try dart\n",
    "        'objective' : ['binary'],\n",
    "        'max_bin':[255], # large max_bin helps improve accuracy but might slow down training progress\n",
    "        'colsample_bytree' : [0.64],\n",
    "        'subsample' : [0.7],\n",
    "}\n",
    "\n",
    "lgbm_grid = grid(models['lgbm'], lgbm_params)\n",
    "print(f'Best params lgbm: {lgbm_grid.best_params_}')\n",
    "print(f'Best score lgbm: {lgbm_grid.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best params lgbm: {'depth': 1, 'iterations': 2000, 'l2_leaf_reg': 1e-20, 'leaf_estimation_iterations': 10, 'loss_function': 'CrossEntropy'}\n",
      "Best score lgbm: 0.7598584828689188\n",
      "Wall time: 1h 19min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_params = {'iterations': [500, 1000, 2000],\n",
    "              'depth': [1, 4, 5, 6],\n",
    "              'loss_function': ['Logloss', 'CrossEntropy'],\n",
    "              'l2_leaf_reg': np.logspace(-20, -19, 3),\n",
    "              'leaf_estimation_iterations': [10],\n",
    "}\n",
    "\n",
    "cat_grid = grid(models['Catboost'], cat_params, 2)\n",
    "print(f'Best params lgbm: {cat_grid.best_params_}')\n",
    "print(f'Best score lgbm: {cat_grid.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4860 candidates, totalling 24300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanderlindberg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params xgb: {'colsample_bytree': 0.6, 'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "Best score xgb: 0.7562589989045685\n",
      "Wall time: 8h 30min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_params = {'min_child_weight': [1, 5, 10],\n",
    "                'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "                'subsample': [0.6, 0.8, 1.0],\n",
    "                'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "                'max_depth': [3, 4, 5],\n",
    "              'n_estimators': [500, 1000],\n",
    "              'learning_rate': [1, .1, .01],\n",
    "}\n",
    "\n",
    "xgb_grid = grid(models['xgb'], xgb_params)\n",
    "print(f'Best params xgb: {xgb_grid.best_params_}')\n",
    "print(f'Best score xgb: {xgb_grid.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best params ada: {'learning_rate': 1, 'n_estimators': 2000}\n",
      "Best score ada: 0.7603071583348466\n",
      "Wall time: 9min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "models['ada'] = AdaBoostClassifier()\n",
    "ada_params = {'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1, 1]}\n",
    "\n",
    "ada_grid = grid(models['ada'], ada_params)\n",
    "print(f'Best params ada: {ada_grid.best_params_}')\n",
    "print(f'Best score ada: {ada_grid.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best params rf: {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 500}\n",
      "Best score rf: 0.7308434896991447\n",
      "Wall time: 16min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models['rf'] = RandomForestClassifier()\n",
    "rf_params = { \n",
    "    'n_estimators': [200, 500, 1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf_grid = grid(models['rf'], rf_params)\n",
    "print(f'Best params rf: {rf_grid.best_params_}')\n",
    "print(f'Best score rf: {rf_grid.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_clf_params = {\n",
    "    'depth': 1, \n",
    "    'iterations': 2000, \n",
    "    'l2_leaf_reg': 1e-20, \n",
    "    'leaf_estimation_iterations': 10, \n",
    "    'loss_function': 'CrossEntropy',\n",
    "    'boosting_type': 'Plain', \n",
    "    'gpu_cat_features_storage': 'CpuPinnedMemory',\n",
    "    'max_ctr_complexity':1,\n",
    "    'iterations':1000,\n",
    "    'depth':1, \n",
    "    'learning_rate':1, \n",
    "    'verbose':False, \n",
    "    'random_state':42, \n",
    "    'task_type':\"GPU\", \n",
    "    'devices':'0:1'\n",
    "}\n",
    "\n",
    "lgbm_clf_params = {\n",
    "    'boosting_type': 'dart', \n",
    "    'colsample_bytree': 0.64, \n",
    "    'learning_rate': 1, \n",
    "    'max_bin': 255, \n",
    "    'n_estimators': 32, \n",
    "    'num_leaves': 16, \n",
    "    'objective': 'binary', \n",
    "    'subsample': 0.7,\n",
    "    'random_state':42, \n",
    "    'device':'gpu'\n",
    "}\n",
    "\n",
    "stacking_models = {}\n",
    "\n",
    "stacking_models['cat'] = CatBoostClassifier(**cat_clf_params)\n",
    "stacking_models['lgbm'] = LGBMClassifier(**lgbm_clf_params)\n",
    "\n",
    "clf = StackingClassifier(estimators = list(stacking_models.items()), final_estimator=LogisticRegression(), cv=10)\n",
    "fit(X_train_pre, y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__cv': 10,\n",
       " 'estimator__estimators': [('lgbm',\n",
       "   LGBMClassifier(device='gpu', random_state=42))],\n",
       " 'estimator__final_estimator__C': 1.0,\n",
       " 'estimator__final_estimator__class_weight': None,\n",
       " 'estimator__final_estimator__dual': False,\n",
       " 'estimator__final_estimator__fit_intercept': True,\n",
       " 'estimator__final_estimator__intercept_scaling': 1,\n",
       " 'estimator__final_estimator__l1_ratio': None,\n",
       " 'estimator__final_estimator__max_iter': 100,\n",
       " 'estimator__final_estimator__multi_class': 'auto',\n",
       " 'estimator__final_estimator__n_jobs': None,\n",
       " 'estimator__final_estimator__penalty': 'l2',\n",
       " 'estimator__final_estimator__random_state': None,\n",
       " 'estimator__final_estimator__solver': 'lbfgs',\n",
       " 'estimator__final_estimator__tol': 0.0001,\n",
       " 'estimator__final_estimator__verbose': 0,\n",
       " 'estimator__final_estimator__warm_start': False,\n",
       " 'estimator__final_estimator': LogisticRegression(),\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__passthrough': False,\n",
       " 'estimator__stack_method': 'auto',\n",
       " 'estimator__verbose': 0,\n",
       " 'estimator__lgbm': LGBMClassifier(device='gpu', random_state=42),\n",
       " 'estimator__lgbm__boosting_type': 'gbdt',\n",
       " 'estimator__lgbm__class_weight': None,\n",
       " 'estimator__lgbm__colsample_bytree': 1.0,\n",
       " 'estimator__lgbm__importance_type': 'split',\n",
       " 'estimator__lgbm__learning_rate': 0.1,\n",
       " 'estimator__lgbm__max_depth': -1,\n",
       " 'estimator__lgbm__min_child_samples': 20,\n",
       " 'estimator__lgbm__min_child_weight': 0.001,\n",
       " 'estimator__lgbm__min_split_gain': 0.0,\n",
       " 'estimator__lgbm__n_estimators': 100,\n",
       " 'estimator__lgbm__n_jobs': -1,\n",
       " 'estimator__lgbm__num_leaves': 31,\n",
       " 'estimator__lgbm__objective': None,\n",
       " 'estimator__lgbm__random_state': 42,\n",
       " 'estimator__lgbm__reg_alpha': 0.0,\n",
       " 'estimator__lgbm__reg_lambda': 0.0,\n",
       " 'estimator__lgbm__silent': 'warn',\n",
       " 'estimator__lgbm__subsample': 1.0,\n",
       " 'estimator__lgbm__subsample_for_bin': 200000,\n",
       " 'estimator__lgbm__subsample_freq': 0,\n",
       " 'estimator__lgbm__device': 'gpu',\n",
       " 'estimator': StackingClassifier(cv=10,\n",
       "                    estimators=[('lgbm',\n",
       "                                 LGBMClassifier(device='gpu', random_state=42))],\n",
       "                    final_estimator=LogisticRegression()),\n",
       " 'n_iter': 10,\n",
       " 'n_jobs': -1,\n",
       " 'param_distributions': {'lgbm__max_depth': [6, 7],\n",
       "  'lgbm__num_leaves': [70, 80]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'random_state': None,\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': 'roc_auc',\n",
       " 'verbose': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack Model accuracy score: 0.7689\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_proba(clf, X_test_split)\n",
    "\n",
    "print_accuracy(prediction, y_test_split, 'stack')\n",
    "\n",
    "\n",
    "real_pred = predict_proba(clf, X_test_pre)\n",
    "\n",
    "f = open(\"./pred.csv\", \"w\")\n",
    "f.write(\"id,target\\n\")\n",
    "id_nr = 50000\n",
    "for v in real_pred[:, 1]:\n",
    "    f.write(f\"{id_nr},{v}\\n\")\n",
    "    id_nr += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, cv\n",
    "\n",
    "cv_dataset = Pool(data=X_train_pre,\n",
    "                  label=y_train,\n",
    "                  cat_features=list(set(X_train_pre.columns).intersection(set(categorical_columns))))\n",
    "\n",
    "params = {\"iterations\": 2000,\n",
    "          \"depth\": 2,\n",
    "          \"learning_rate\": 1,\n",
    "          \"loss_function\": \"Logloss\",\n",
    "          \"verbose\": False,\n",
    "          \"roc_file\": \"roc-file\"}\n",
    "\n",
    "scores = cv(cv_dataset,\n",
    "            params,\n",
    "            fold_count=2, \n",
    "            plot=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
